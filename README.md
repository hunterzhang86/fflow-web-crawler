æœ¬çˆ¬è™«ä½¿ç”¨Pythonå¼€å‘,é€šè¿‡[åˆå§‹åŒ–ä¸€ä¸ªScrapyé¡¹ç›®](https://docs.scrapy.org/en/latest/intro/tutorial.html#creating-a-project)å¹¶å®ç°ä¸€ä¸ªè‡ªå®šä¹‰çˆ¬è™«ã€‚è¯¥çˆ¬è™«é…å¤‡äº†`parse_page`å‡½æ•°,æ¯å½“çˆ¬è™«è®¿é—®ä¸€ä¸ªç½‘é¡µæ—¶éƒ½ä¼šè°ƒç”¨æ­¤å‡½æ•°ã€‚è¿™ä¸ªå›è°ƒå‡½æ•°å°†ç½‘é¡µä¸Šçš„æ–‡æœ¬åˆ†å‰²æˆå—,ä¸ºæ¯ä¸ªå—ç”Ÿæˆå‘é‡åµŒå…¥,å¹¶å°†è¿™äº›å‘é‡æ›´æ–°æ’å…¥åˆ°æ‚¨çš„Upstashå‘é‡æ•°æ®åº“ä¸­ã€‚å­˜å‚¨åœ¨æˆ‘ä»¬æ•°æ®åº“ä¸­çš„æ¯ä¸ªå‘é‡éƒ½åŒ…å«åŸå§‹æ–‡æœ¬å’Œç½‘ç«™URLä½œä¸ºå…ƒæ•°æ®ã€‚

### é…ç½®ç¯å¢ƒå˜é‡

åœ¨è¿è¡Œçˆ¬è™«ä¹‹å‰,æˆ‘ä»¬éœ€è¦é…ç½®ç¯å¢ƒå˜é‡ã€‚å®ƒä»¬è®©æˆ‘ä»¬å¯ä»¥å®‰å…¨åœ°å­˜å‚¨æ•æ„Ÿä¿¡æ¯,æ¯”å¦‚ä¸ OpenAI æˆ– Upstash Vector é€šä¿¡æ‰€éœ€çš„APIå¯†é’¥ã€‚

å¦‚æœæ‚¨è¿˜æ²¡æœ‰ Upstashå‘é‡æ•°æ®åº“,è¯·åœ¨[è¿™é‡Œ](https://console.upstash.com/vector)åˆ›å»ºä¸€ä¸ª,å¹¶å°†å‘é‡ç»´åº¦è®¾ç½®ä¸º1536ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œè®¾ç½®1536æ˜¯å› ä¸ºè¿™æ˜¯æˆ‘ä»¬å°†ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹æ‰€éœ€çš„æ•°é‡ã€‚

åº”è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡:

```
# Upstash Vectorå‡­è¯å¯åœ¨æ­¤å¤„è·å–: https://console.upstash.com/vector
UPSTASH_VECTOR_REST_URL=****
UPSTASH_VECTOR_REST_TOKEN=****

# OpenAIå¯†é’¥å¯åœ¨æ­¤å¤„è·å–: https://platform.openai.com/api-keys
OPENAI_API_KEY=****
```
### å®‰è£…æ‰€éœ€çš„Pythonåº“

è¦å®‰è£…è¿™äº›åº“,æˆ‘ä»¬å»ºè®®è®¾ç½®ä¸€ä¸ªè™šæ‹ŸPythonç¯å¢ƒã€‚åœ¨å¼€å§‹å®‰è£…ä¹‹å‰,è¯·å¯¼èˆªåˆ°`fflowwebcrawler`ç›®å½•ã€‚

è¦è®¾ç½®è™šæ‹Ÿç¯å¢ƒ,é¦–å…ˆå®‰è£…`virtualenv`åŒ…:

```bash
pip install virtualenv
```

ç„¶å,åˆ›å»ºä¸€ä¸ªæ–°çš„è™šæ‹Ÿç¯å¢ƒå¹¶æ¿€æ´»å®ƒ:

```bash
# åˆ›å»ºç¯å¢ƒ
python3 -m venv venv

# æ¿€æ´»ç¯å¢ƒ
source venv/bin/activate
```

æœ€å,ä½¿ç”¨ `requirements.txt` å®‰è£…æ‰€éœ€çš„åº“:

```bash
pip install -r requirements.txt
```

</details>

</br>

è®¾ç½®è¿™äº›ç¯å¢ƒå˜é‡å,æˆ‘ä»¬å‡ ä¹å‡†å¤‡å¥½è¿è¡Œçˆ¬è™«äº†ã€‚ä¸‹ä¸€æ­¥æ¶‰åŠé…ç½®çˆ¬è™«æœ¬èº«,ä¸»è¦é€šè¿‡`crawler.yaml`æ–‡ä»¶å®Œæˆã€‚æ­¤å¤–,è¿˜å¿…é¡»åœ¨`settings.py`æ–‡ä»¶ä¸­å¤„ç†ä¸€ä¸ªå…³é”®è®¾ç½®ã€‚

```yaml
crawler:
  start_urls:
    - https://www.some.domain.com
  link_extractor:
    allow: '.*some\.domain.*'
    deny:
      - "#"
      - '\?'
      - about
index:
  openAI_embedding_model: text-embedding-ada-002
  text_splitter:
    chunk_size: 1000
    chunk_overlap: 100
```

åœ¨`crawler`éƒ¨åˆ†,æœ‰ä¸¤ä¸ªå­éƒ¨åˆ†:

- `start_urls`: æˆ‘ä»¬çš„çˆ¬è™«å°†å¼€å§‹æœç´¢çš„å…¥å£ç‚¹
- `link_extractor`: ä½œä¸ºå‚æ•°ä¼ é€’ç»™[`scrapy.linkextractors.LinkExtractor`](https://docs.scrapy.org/en/latest/topics/link-extractors.html)çš„å­—å…¸ã€‚ä¸€äº›é‡è¦å‚æ•°æ˜¯:
  - `allow`: åªæå–åŒ¹é…ç»™å®šæ­£åˆ™è¡¨è¾¾å¼çš„é“¾æ¥
  - `allow_domains`: åªæå–åŒ¹é…ç»™å®šåŸŸåçš„é“¾æ¥
  - `deny`: æ‹’ç»åŒ¹é…ç»™å®šæ­£åˆ™è¡¨è¾¾å¼çš„é“¾æ¥

åœ¨`index`éƒ¨åˆ†,æœ‰ä¸¤ä¸ªå­éƒ¨åˆ†:

- `openAI_embedding_model`: è¦ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹
- `test_splitter`: ä½œä¸ºå‚æ•°ä¼ é€’ç»™[`langchain.text_splitter.RecursiveCharacterTextSplitter`](https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html)çš„å­—å…¸


å°±æ˜¯è¿™æ ·! ğŸ‰ æˆ‘ä»¬å·²ç»é…ç½®äº†çˆ¬è™«,å‡†å¤‡ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿è¡Œå®ƒ:

```
scrapy crawl configurable --logfile crawler.log
```

è¯·æ³¨æ„,è¿è¡Œè¿™ä¸ªå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ã€‚æ‚¨å¯ä»¥é€šè¿‡æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶`fflowwebcrawler.log`æˆ–å¦‚ä¸‹æ‰€ç¤ºçš„Upstashå‘é‡æ•°æ®åº“ä»ªè¡¨æ¿çš„æŒ‡æ ‡æ¥ç›‘æ§è¿›åº¦ã€‚
```